{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DigitRecognizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIGcq7i23TQk"
      },
      "source": [
        "# Digit Recognition using CNN\n",
        "\n",
        "This notebook contains solution for the famous digit recognition competition hosted on Kaggle.\n",
        "We will perform the following operations throughout our code pipeline:\n",
        "\n",
        "1.   ETL(Extract, transform and load) pipeline.\n",
        "2.   Creating a custom dataset class for preparing our dataset.\n",
        "3.   Implementing a model in pytorch from scratch.\n",
        "4.   Performing hyper parameter tuning of the model using runbuilder and runmanager class.\n",
        "5.   Evaluating the model performance using tensorboard and pandas.\n",
        "6.   getting the predictions for test dataset.\n",
        "7.   Exporting the model using onnx.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLQnNhZr6On7"
      },
      "source": [
        "# Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB6MWw88knHn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transform\n",
        "from torch.utils.data import Dataset, DataLoader,random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from collections import OrderedDict, namedtuple\n",
        "from itertools import product\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "import json\n",
        "torch.set_deterministic(True)\n",
        "import torch.onnx\n",
        "torch.manual_seed(0)\n",
        "from IPython.display import clear_output\n",
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIKlbmOe6bSd"
      },
      "source": [
        "# Importing dataset\n",
        "\n",
        "I have imported the dataset using google drive.\n",
        "You can change this code as per your location of training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfN_w0z5k4L2"
      },
      "source": [
        "!unzip /content/drive/MyDrive/digit-recognizer.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH8XmQ_T3R2Z"
      },
      "source": [
        "# Creating a dataset\n",
        "Now we'll create a custom dataset class.\n",
        "This class will inherit *Dataset* class implemented by pytorch.\n",
        " \n",
        "\n",
        "*   The digitRecognizerDataset inherits Dataset class and this class act as a dataset provider for our dataloader.\n",
        "\n",
        "*   We'll implement two methods in our class\n",
        "\n",
        "1. \"__getitem__(self,idx)\": This method will take as input an index and return data at that index\n",
        "2.  \"__len__(self)\" : This method will return the length of the dataset\n",
        "\n",
        "*   This class will also apply all the transformations that we provide on the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHQ72VjUlg17"
      },
      "source": [
        "class digitRecognizerDataset(Dataset):\n",
        "  def __init__(self,path,train=True,transform=None):\n",
        "    self.path = path\n",
        "    self.train = train\n",
        "    self.transform = transform\n",
        "    self.df = pd.read_csv(self.path)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    if(self.train):\n",
        "      label = self.df.iloc[idx].values[0]\n",
        "      image = self.df.iloc[idx].values[1:].reshape(28,28,1)/255\n",
        "      if(self.transform):\n",
        "        image = self.transform(image)\n",
        "      return image,label\n",
        "    else:\n",
        "      image = self.df.iloc[idx].values.reshape(28,28,1)/255\n",
        "      if(self.transform):\n",
        "        image = self.transform(image)\n",
        "      return image\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWIebVlk8V_g"
      },
      "source": [
        "# Transformations\n",
        "Not we'll create some transformations for our train and test set.\n",
        " \n",
        "\n",
        "* We can have multiple transformations based on the dataset we are dealing and what type of input is expected by our network.\n",
        "* We can even have different transformations for train and test dataset based on our usecase. For now we'll have the same transformation for both our dataset \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrmKClngpu4F"
      },
      "source": [
        "train_transform = transform.Compose([\n",
        "                                     transform.ToTensor()\n",
        "])\n",
        "test_transform = transform.Compose([\n",
        "                                    transform.ToTensor()\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "714QBQe29E0J"
      },
      "source": [
        "# DataLoader\n",
        "DataLoader makes use of our dataset class to break our data into batches. This helps during training and testing since we can load as much data as we want based on our system memory and training performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tsWrGTLlibD"
      },
      "source": [
        "train_set = digitRecognizerDataset('train.csv',transform=train_transform)\n",
        "train_size = int(0.8*len(train_set))\n",
        "validation_size = int(len(train_set) - train_size)\n",
        "train_set,validation_set = random_split(train_set,[train_size,validation_size])\n",
        "train_loader = DataLoader(train_set,shuffle=True,batch_size=8)\n",
        "validation_loader = DataLoader(validation_set,shuffle=True,batch_size=100)\n",
        "test_set = digitRecognizerDataset('test.csv',train=False,transform=test_transform)\n",
        "test_loader = DataLoader(test_set,batch_size=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBWxpy089Z2P"
      },
      "source": [
        "# Display Image\n",
        "The first thing we need to do before proceeding with designing our model is to get accustomed to our data. We'll make use \"make_grid\" method to display our images side by side in form of grid.\n",
        "We can even use matplotlib to display our images and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9FAudSYmqNv"
      },
      "source": [
        "def displayImages(images,labels):\n",
        "  plt.figure(figsize=(15,15))\n",
        "  print(labels)\n",
        "  images = images/2 + 0.5\n",
        "  plt.imshow(np.transpose(images,[1,2,0]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()\n",
        "images,labels = next(iter(train_loader))\n",
        "grid = torchvision.utils.make_grid(images)\n",
        "displayImages(grid,labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n866MMY98Qs"
      },
      "source": [
        "# Designing our model\n",
        "The first and foremost thing to keep in mind while designing any model is to be aware of what of data we are dealing with. Since in this notebook we are going to deal with image data, we'll use cnn model for this problem.\n",
        "We'll create our model in 3 steps:\n",
        "\n",
        "\n",
        "\n",
        "1.   Create a class and inherit nn.Module(this class wraps all the details regarding weight initialization, connecting the layers etc).\n",
        "2.   in the __init__ method create the model architecture using Sequential method.\n",
        "3. Create a forward method. This method gets triggered automatically when we pass data to the instance of this class. This automatic method call is internally handled by nn.module class\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejNdrADcdemY"
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Network,self).__init__()\n",
        "    self.network = nn.Sequential(\n",
        "              nn.Conv2d(in_channels=1,out_channels=20,kernel_size=3), # output(26,26)\n",
        "              nn.ReLU(),\n",
        "              nn.BatchNorm2d(20),\n",
        "              nn.MaxPool2d(kernel_size=3,stride=2),                    # output(12,12)\n",
        "\n",
        "              nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3),  #output (10,10)\n",
        "              nn.ReLU(),\n",
        "              nn.BatchNorm2d(32),\n",
        "              nn.Dropout(0.25),\n",
        "\n",
        "              nn.Conv2d(in_channels=32,out_channels=48,kernel_size=3), #output (8,8)\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(0.25),\n",
        "\n",
        "              nn.Flatten(),\n",
        "              nn.Linear(in_features=8*8*48,out_features=500),\n",
        "              nn.ReLU(),\n",
        "              nn.BatchNorm1d(num_features=500),\n",
        "              nn.Linear(in_features=500,out_features=10)\n",
        "    )\n",
        "\n",
        "  def forward(self,tensor):\n",
        "    return self.network(tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu-OK6bV_KOO"
      },
      "source": [
        "# Creating a run Builder class\n",
        "The run builder class will take in all our hyperparameters that we want to tune and give us all possible combinations of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aayCR0ugr2tI"
      },
      "source": [
        "params = OrderedDict(\n",
        "    batch_size = [16,32,64],\n",
        "    lr=[0.1,0.01,0.05],\n",
        "    epochs=[10,20,50]\n",
        ")\n",
        "class RunBuilder():\n",
        "  @staticmethod\n",
        "  def get_runs(params):\n",
        "    Run = namedtuple('Run',params.keys())\n",
        "    runs = []\n",
        "    for run in product(*params.values()):\n",
        "      runs.append(Run(*run))\n",
        "    return runs\n",
        "for param in RunBuilder.get_runs(params):\n",
        "  print(param._asdict())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pOB_2FD_YvX"
      },
      "source": [
        "# Run Manager\n",
        "The run manager is the most complex yet elegant part of this notebook.It acts as a abstract layer over our training loop to track our model training cycle.\n",
        "It will perform the following tasks:\n",
        "\n",
        "*   Keep track of number of epochs and runs executed\n",
        "*   performance of model on training and validation set when trained on different hyperparameters\n",
        "\n",
        "\n",
        "*   Save the data for each run in tensorboard Summary Writer for later evaluation \n",
        "*   Saving the result of all the runs in a csv file\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4-HEt_YAG_i"
      },
      "source": [
        "class RunManager():\n",
        "  def __init__(self):\n",
        "    self.run_start_time = None\n",
        "    self.run_count = 0\n",
        "    self.run_params = None\n",
        "    self.run_data = []\n",
        "\n",
        "    self.epoch_start_time = None\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_correct_preds = 0\n",
        "    self.epoch_count=0\n",
        "    self.correct_val_preds = 0\n",
        "    self.loader = None\n",
        "    self.network = None\n",
        "    self.params = None\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def eval(self):\n",
        "    self.network.eval()\n",
        "    for images,labels in validation_loader:\n",
        "      images,labels = images.to(device),labels.to(device)\n",
        "      preds = self.network(images.float())\n",
        "      self.correct_val_preds +=self.correct_preds(preds,labels)\n",
        "    self.network.train()\n",
        "    return self.correct_val_preds/len(validation_loader.dataset)\n",
        "\n",
        " \n",
        "  def start_run(self,network,loader,params):\n",
        "    self.network = network\n",
        "    self.loader = loader\n",
        "    self.run_params = params\n",
        "\n",
        "    self.run_count+=1\n",
        "    self.run_start_time = time.time()\n",
        "    self.tb = SummaryWriter(comment=f'-{self.run_params}')\n",
        "\n",
        "    images,labels = next(iter(loader))\n",
        "    images,labels = images.to(device).float(),labels.to(device)\n",
        "    grid = torchvision.utils.make_grid(images)\n",
        "    self.tb.add_image(\"images\",grid)\n",
        "    self.tb.add_graph(self.network,images)\n",
        "  \n",
        "  def end_run(self):\n",
        "    self.tb.close()\n",
        "    self.epoch_count = 0\n",
        "\n",
        "\n",
        "  def start_epoch(self):\n",
        "    self.epoch_count+=1\n",
        "    self.epoch_start_time = time.time()\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_correct_preds = 0\n",
        "    self.correct_val_preds = 0\n",
        "\n",
        "  def end_epoch(self):\n",
        "    epoch_duration = time.time() - self.epoch_start_time\n",
        "    run_duration = time.time() - self.run_start_time\n",
        "    loss = self.epoch_loss/len(self.loader.dataset)\n",
        "    accuracy = self.epoch_correct_preds/len(self.loader.dataset)\n",
        "    \n",
        "    self.tb.add_scalar('Accuracy',accuracy,self.epoch_count)\n",
        "    self.tb.add_scalar('Loss',loss,self.epoch_count)\n",
        "    for name,param in self.network.named_parameters():\n",
        "      self.tb.add_histogram(name,param,self.epoch_count)\n",
        "      self.tb.add_histogram(f'{name}.grad',param.grad,self.epoch_count)\n",
        "    results = OrderedDict()\n",
        "    results['loss'] = loss\n",
        "    results['Train Accuracy'] = accuracy\n",
        "    results['Val Accuracy'] = self.eval()\n",
        "    results['epoch_duration'] = epoch_duration\n",
        "    results['run_duration'] = run_duration\n",
        "    results['run'] = self.run_count\n",
        "    results['epoch'] = self.epoch_count\n",
        "    for k,v in self.run_params._asdict().items(): results[k]=v\n",
        "    self.run_data.append(results)\n",
        "    df = pd.DataFrame.from_dict(self.run_data,orient='columns')\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    display(df)\n",
        "\n",
        "  def track_loss(self,loss):\n",
        "    self.epoch_loss+=loss.item()*self.loader.batch_size\n",
        "\n",
        "  def track_correct_preds(self,preds,labels):\n",
        "    self.epoch_correct_preds+=self.correct_preds(preds,labels)\n",
        "  \n",
        "  @torch.no_grad()\n",
        "  def correct_preds(self,preds,labels):\n",
        "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
        "\n",
        "  def save(self,filename):\n",
        "    pd.DataFrame.from_dict(\n",
        "        self.run_data,\n",
        "        orient='columns'\n",
        "    ).to_csv(f'{filename}.csv')\n",
        "\n",
        "    with open(f'{filename}.json','w',encoding='utf-8') as f:\n",
        "      json.dump(self.run_data,f,ensure_ascii=False,indent=4)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_9BSnnlAShT"
      },
      "source": [
        "# Training loop\n",
        "Finally we'll train our model with different parameters. You can pass in as many parameters as you want. Try different combinations of params and tweak your model accordingly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA0Mt7t3ErpL"
      },
      "source": [
        "m = RunManager()\n",
        "params = OrderedDict(\n",
        "    batch_size = [64,128],\n",
        "    lr=[0.001],\n",
        "    epochs=[100]\n",
        ")\n",
        "for run in RunBuilder.get_runs(params):\n",
        "  network = Network()\n",
        "  network = network.to(device)\n",
        "  optimizer = optim.Adam(network.parameters(),lr=run.lr)\n",
        "  loader = DataLoader(train_set,shuffle=True,batch_size=run.batch_size)\n",
        "  m.start_run(network,loader,run)\n",
        "  for epoch in range(run.epochs):\n",
        "    m.start_epoch()\n",
        "    for batch in loader:\n",
        "      images,labels = batch\n",
        "      images,labels = images.to(device).float(),labels.to(device)\n",
        "      preds = network(images)\n",
        "      loss = F.cross_entropy(preds,labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      m.track_loss(loss)\n",
        "      m.track_correct_preds(preds,labels)\n",
        "    m.end_epoch()\n",
        "  m.end_run()\n",
        "m.save(\"results\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOtYZ8iS7i5I"
      },
      "source": [
        "df = pd.read_csv('results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdgBa27pTXt7"
      },
      "source": [
        "df.sort_values(by=[\"Train Accuracy\",\"Val Accuracy\"],ascending=False).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa1jFYHXTfsM"
      },
      "source": [
        "df.sort_values(by=[\"Val Accuracy\",\"Train Accuracy\"],ascending=False).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzM5V_yyApK-"
      },
      "source": [
        "# Final Train\n",
        "Finally we'll train the model based on the results of evalution and training set accuracy calculated above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kCMm7klT2Ob"
      },
      "source": [
        "import copy\n",
        "epochs=50\n",
        "batch_size=128\n",
        "lr=0.001\n",
        "network = Network()\n",
        "network = network.to(device)\n",
        "train_loader = DataLoader(train_set,batch_size=batch_size)\n",
        "optimizer = optim.Adam(network.parameters(),lr=lr)\n",
        "min_loss=100000\n",
        "best_model = None\n",
        "for _ in tqdm_notebook(range(epochs)):\n",
        "  total_loss=0\n",
        "  for batch in train_loader:\n",
        "    images,labels = batch\n",
        "    images,labels = images.to(device),labels.to(device)\n",
        "    preds = network(images.float())\n",
        "    loss = F.cross_entropy(preds,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    total_loss+=loss.item()\n",
        "  if(total_loss<min_loss):\n",
        "    min_loss = total_loss\n",
        "    best_model = copy.deepcopy(network.state_dict())\n",
        "  print(\"loss\",loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZEP-wAUBB7e"
      },
      "source": [
        "# Loading our best model\n",
        "Now we'll load the model and set it to eval mode. Eval mode switches of batchnorm optimization and dropout layer in our model. It also set the gradient calculation to False. So that no computaional graph is created while inferencing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUlSQ-VzW6nA"
      },
      "source": [
        "network.load_state_dict(best_model)\n",
        "network.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9GrxqYEBf8u"
      },
      "source": [
        "# Using Onnx\n",
        "Onnx is a platform independent file format used to save DL and ML models so that they can be used across different frameworks and hardwares without any optimization to be done by developer.\n",
        "\n",
        "We'll use this onnx file to create our application."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lytin6JpPO2t"
      },
      "source": [
        "onnx_model_path = \"model.onnx\"\n",
        "images,labels = next(iter(train_loader))\n",
        "torch.onnx.export(network.to(device),images.to(device).float(),onnx_model_path,verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhV1fMZkB_3Q"
      },
      "source": [
        "# Kaggle Time\n",
        "Now you can run the model and get the predictions for your test set. You can then submit the submission csv to the kaggle problem.[Digit Recognizer on kaggle](https://www.kaggle.com/c/digit-recognizer/data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUyDHPLmZFFq"
      },
      "source": [
        "predictions = []\n",
        "for image in test_loader:\n",
        "  preds = network(image.to(device).float())\n",
        "  predictions.extend(F.softmax(preds,dim=1).argmax(dim=1))\n",
        "final_predictions =list(map(int,predictions))\n",
        "object = {\n",
        "    \"ImageId\":list(range(1,len(predictions)+1)),\n",
        "    \"Label\":final_predictions\n",
        "}\n",
        "result = pd.DataFrame(object).reset_index(drop=True)\n",
        "result.to_csv(\"kaggle_submission.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}